# -*- coding: utf-8 -*-
"""cv@new_pro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVqh_HPDjy5DnIP7T7piNHQ_WDxXKHvx
"""

!pip install -q sentence-transformers scikit-learn pandas matplotlib nltk

import pandas as pd
import numpy as np
import random
import re
import matplotlib.pyplot as plt
import nltk
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
from sentence_transformers import SentenceTransformer, InputExample, losses, util
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator
from torch.utils.data import DataLoader
from google.colab import files

nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))

def preprocess(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)           # Remove punctuation
    text = re.sub(r'\s+', ' ', text).strip()      # Normalize whitespace
    tokens = [word for word in text.split() if word not in stop_words]
    return " ".join(tokens)

uploaded = files.upload()  # Upload a CSV file named new_data.csv
df = pd.read_csv("synthetic_resumes_200.csv")
df.fillna("", inplace=True)

# Preprocess text columns
df['job_description'] = df['job_description'].apply(preprocess)
df['cv_text'] = df['cv_text'].apply(preprocess)

examples = [
    InputExample(texts=[row['job_description'], row['cv_text']], label=float(row['label'] or 0.0))
    for _, row in df.iterrows()
]

model = SentenceTransformer('all-mpnet-base-v2')

# Create dataloaders
train_dataloader = DataLoader(examples, shuffle=True, batch_size=16)
train_loss = losses.CosineSimilarityLoss(model)

# 10% validation set
val_examples = examples[:int(0.1 * len(examples))]
evaluator = EmbeddingSimilarityEvaluator.from_input_examples(val_examples)

model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    evaluator=evaluator,
    epochs=5,
    evaluation_steps=100,
    warmup_steps=100,
    show_progress_bar=True,
    output_path="./best_model"
)

true_scores = [ex.label for ex in val_examples]
pred_scores = [
    util.cos_sim(model.encode(ex.texts[0], convert_to_tensor=True),
                 model.encode(ex.texts[1], convert_to_tensor=True)).item()
    for ex in val_examples
]

# Regression metrics
mae = mean_absolute_error(true_scores, pred_scores)
r2 = r2_score(true_scores, pred_scores)

# Binarize for classification metrics
true_binary = [1 if s >= 0.5 else 0 for s in true_scores]
pred_binary = [1 if s >= 0.5 else 0 for s in pred_scores]
acc = accuracy_score(true_binary, pred_binary)
f1 = f1_score(true_binary, pred_binary)

print("\nüîç Evaluation Metrics on Validation Set:")
print(f"MAE: {mae:.4f}, R2: {r2:.4f}")
print(f"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

labels = [0, 1]  # Ensure both classes are shown
cm = confusion_matrix(true_binary, pred_binary, labels=labels)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Not Match", "Match"])
disp.plot(cmap='Blues')
plt.title("Confusion Matrix on Validation Set")
plt.show()

print("\nüìù Enter CVs (type 'exit' to stop):")
user_cvs = []
while True:
    cv = input(f"CV {len(user_cvs)+1}: ")
    if cv.lower() == 'exit':
        break
    user_cvs.append(preprocess(cv))

job_desc = preprocess(input("\nüßë‚Äçüíº Job description: "))

# Load fine-tuned model
model = SentenceTransformer('./best_model')

job_embedding = model.encode(job_desc, convert_to_tensor=True)

ranked = []
for cv_text in user_cvs:
    cv_embedding = model.encode(cv_text, convert_to_tensor=True)
    score = util.cos_sim(job_embedding, cv_embedding).item()
    ranked.append((cv_text, score))

ranked = sorted(ranked, key=lambda x: x[1], reverse=True)

print("\nüìä Ranked CVs for the Job:\n")
print("| Rank | CV Text (Preview)                                | Suitability Score |")
print("|------|--------------------------------------------------|-------------------|")
for i, (cv_text, score) in enumerate(ranked, 1):
    print(f"| {i:<4} | {cv_text[:50]:<50} | {score:.2f}              |")

texts = [cv[:30] + "..." for cv, _ in ranked]
scores = [score for _, score in ranked]

plt.figure(figsize=(10, 5))
plt.barh(texts[::-1], scores[::-1], color='skyblue')
plt.xlabel('Suitability Score')
plt.title('Ranked CVs for Job Description')
plt.tight_layout()
plt.show()

